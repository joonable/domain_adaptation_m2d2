{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델은 반드시 gpt-2 데이터 다르게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from datetime import date, datetime\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path_format = \"/rds/general/user/jj1122/home/projects/m2d2/dataset/{model_id}/models\"\n",
    "# ckpt_path_format = \"/checkpoint-{ckpt}\"\n",
    "# cache_dir = \"/rds/general/user/jj1122/ephemeral/.cache/huggingface\"\n",
    "# General_referece\n",
    "# list_of_datasets = [\n",
    "#     \"cs_l1\",\n",
    "#     \"nlin_l1\",\n",
    "#     \"Health_and_fitness\",\n",
    "#     \"Natural_and_physical_sciences\",\n",
    "#     \"Religion_and_belief_systems\",\n",
    "#     \"Culture_and_the_arts\",\n",
    "#     \"General_referece\",\n",
    "#     \"econ_l1\",\n",
    "#     \"History_and_events\",\n",
    "#     \"Human_activites\",\n",
    "#     \"Mathematics_and_logic\",\n",
    "# #     \"astro-ph_l1\",\n",
    "# #     \"cond-mat_l1\",\n",
    "#     \"eess_l1\",\n",
    "# #     \"math_l1\",\n",
    "# #     \"physics_l1 (ERROR)\",\n",
    "#     \"q-bio_l1\",\n",
    "#     \"q-fin_l1\",\n",
    "#     \"stat_l1\",\n",
    "#     \"Philosophy\",\n",
    "#     \"Philosophy_and_thinking\",\n",
    "#     \"Society_and_social_sciences\",\n",
    "#     \"Technology_and_applied_sciences\",\n",
    "\n",
    "# ]\n",
    "\n",
    "device_id = \"mps\"\n",
    "today_dt = date.today().strftime(\"%y%m%d\")\n",
    "\n",
    "model_id = \"gpt2\"\n",
    "model_path = \"gpt2\"\n",
    "model_type = \"zsh\"\n",
    "\n",
    "output_file = f\"./output_logs/{today_dt}_{model_type}.json\"\n",
    "ds = \"Religion_and_belief_systems\"\n",
    "stride = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model, Tokeniser, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset m2d2 (/Users/joon/.cache/huggingface/datasets/machelreid___m2d2/Religion_and_belief_systems/0.0.0/eb235f33a5de3163c10549b7f63c906910539c8a8c0ec5ade1285ccbf5067d00)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4232477afc4f878b295bb3baa09c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device_id)\n",
    "model.eval()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"machelreid/m2d2\", ds#, cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation & Grouping Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5516181 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5387/5387 [00:02<00:00, 2377.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_input_ids = {}\n",
    "\n",
    "for gubun in [\"validation\"]: # [\"train\", \"validation\", \"test\"]:\n",
    "    if gubun == \"train\": continue\n",
    "\n",
    "    # TOKENISATION\n",
    "    encodings = tokenizer(\"\\n\".join(dataset[gubun][\"text\"]), return_tensors=\"pt\")\n",
    "\n",
    "    # GROUPING TEXT\n",
    "    with torch.no_grad():\n",
    "        max_length = model.config.n_positions\n",
    "        nlls = []\n",
    "        list_input_ids = []\n",
    "        for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
    "            begin_loc = max(i + stride - max_length, 0)\n",
    "            end_loc = min(i + stride, encodings.input_ids.size(1))\n",
    "            trg_len = end_loc - i  # may be different from stride on last loop\n",
    "            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device_id)\n",
    "            target_ids = input_ids.clone()\n",
    "            target_ids[:, :-trg_len] = -100\n",
    "            list_input_ids.append(input_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'William Henry Willimon',\n",
       " '',\n",
       " 'William Henry Willimon (born May 15, 1946) is an American theologian and bishop in the United Methodist Church, retired, who for eight years served the North Alabama Conference. He is currently Professor of the Practice of Christian Ministry and Director of the Doctor of Ministry program at Duke Divinity School. He is former Dean of the Chapel at Duke University and is considered by many as one of America\\'s best-known and most influential preachers. A Pulpit & Pew Research on Pastoral Leadership survey determined that he was one of the two most frequently read writers by pastors in mainline Protestantism alongside the Roman Catholic writer Henri Nouwen. His books have sold over a million copies. He is also Editor-At-Large of \"The Christian Century\". His 2019 memoir \"Accidental Preacher\" was released to wide acclaim, described by Justo L. Gonzalez as \"An exceptional example of theology at its best.\"',\n",
       " 'Biography.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][\"text\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  198, 17121,  8616,  2561, 20473,   198,   198, 17121,  8616,  2561])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings['input_ids'][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ċ', 'William', 'ĠHenry', 'ĠWill', 'imon', 'Ċ', 'Ċ', 'William', 'ĠHenry', 'ĠWill']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encodings['input_ids'][0][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5516181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(encodings['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198, 17121,  8616,  ..., 32390,  5535,    11]], device='mps:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input_ids[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ċ', 'William', 'ĠHenry', 'ĠWill', 'imon', 'Ċ', 'Ċ', 'William', 'ĠHenry', 'ĠWill']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(list_input_ids[0][0][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Trainer pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=8):   0%|          | 0/1378270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=8):   0%|          | 0/108776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=8):   0%|          | 0/108776 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples['text'])\n",
    "    # clm input could be much much longer than block_size\n",
    "    return output\n",
    "    \n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    remove_columns=['text'],\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5414308"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(chain(*(tokenized_datasets['validation']['input_ids']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "block_size = tokenizer.model_max_length\n",
    "if block_size > 1024:\n",
    "    block_size = 1024\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    load_from_cache_file=True,\n",
    "    desc=f\"Grouping texts in chunks of {block_size}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'William Henry Willimon',\n",
       " '',\n",
       " 'William Henry Willimon (born May 15, 1946) is an American theologian and bishop in the United Methodist Church, retired, who for eight years served the North Alabama Conference. He is currently Professor of the Practice of Christian Ministry and Director of the Doctor of Ministry program at Duke Divinity School. He is former Dean of the Chapel at Duke University and is considered by many as one of America\\'s best-known and most influential preachers. A Pulpit & Pew Research on Pastoral Leadership survey determined that he was one of the two most frequently read writers by pastors in mainline Protestantism alongside the Roman Catholic writer Henri Nouwen. His books have sold over a million copies. He is also Editor-At-Large of \"The Christian Century\". His 2019 memoir \"Accidental Preacher\" was released to wide acclaim, described by Justo L. Gonzalez as \"An exceptional example of theology at its best.\"',\n",
       " 'Biography.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][\"text\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 1378270\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 108776\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 108776\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [17121, 8616, 2561, 20473], [], [17121, 8616, 2561, 20473, 357, 6286, 1737, 1315, 11, 22717, 8, 318, 281, 1605, 37275, 666, 290, 24233, 287, 262, 1578, 38029, 4564, 11, 9880, 11, 508, 329, 3624, 812, 4983, 262, 2258, 9266, 8785, 13, 679, 318, 3058, 8129, 286, 262, 19939, 286, 4302, 9475, 290, 5890, 286, 262, 9356, 286, 9475, 1430, 379, 11083, 33170, 3961, 13, 679, 318, 1966, 11325, 286, 262, 32939, 379, 11083, 2059, 290, 318, 3177, 416, 867, 355, 530, 286, 2253, 338, 1266, 12, 4002, 290, 749, 14212, 662, 17892, 13, 317, 21624, 15544, 1222, 21805, 4992, 319, 11303, 6864, 26935, 5526, 5295, 326, 339, 373, 530, 286, 262, 734, 749, 6777, 1100, 8786, 416, 43978, 287, 50114, 25310, 1042, 7848, 262, 7993, 7835, 6260, 44485, 44599, 21006, 13, 2399, 3835, 423, 2702, 625, 257, 1510, 9088, 13, 679, 318, 635, 12058, 12, 2953, 12, 21968, 286, 366, 464, 4302, 13641, 1911, 2399, 13130, 24649, 366, 17320, 35182, 3771, 3493, 1, 373, 2716, 284, 3094, 21684, 11, 3417, 416, 2329, 78, 406, 13, 24416, 355, 366, 2025, 15313, 1672, 286, 24383, 379, 663, 1266, 526], [23286, 4867, 13]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"validation\"][\"input_ids\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['William', 'ĠHenry', 'ĠWill', 'imon', 'William', 'ĠHenry', 'ĠWill', 'imon', 'Ġ(', 'born', 'ĠMay', 'Ġ15', ',', 'Ġ1946', ')', 'Ġis', 'Ġan', 'ĠAmerican', 'Ġtheolog', 'ian', 'Ġand', 'Ġbishop', 'Ġin', 'Ġthe', 'ĠUnited', 'ĠMethodist', 'ĠChurch', ',', 'Ġretired', ',', 'Ġwho', 'Ġfor', 'Ġeight', 'Ġyears', 'Ġserved', 'Ġthe', 'ĠNorth', 'ĠAlabama', 'ĠConference', '.', 'ĠHe', 'Ġis', 'Ġcurrently', 'ĠProfessor', 'Ġof', 'Ġthe', 'ĠPractice', 'Ġof', 'ĠChristian', 'ĠMinistry', 'Ġand', 'ĠDirector', 'Ġof', 'Ġthe', 'ĠDoctor', 'Ġof', 'ĠMinistry', 'Ġprogram', 'Ġat', 'ĠDuke', 'ĠDivinity', 'ĠSchool', '.', 'ĠHe', 'Ġis', 'Ġformer', 'ĠDean', 'Ġof', 'Ġthe', 'ĠChapel', 'Ġat', 'ĠDuke', 'ĠUniversity', 'Ġand', 'Ġis', 'Ġconsidered', 'Ġby', 'Ġmany', 'Ġas', 'Ġone', 'Ġof', 'ĠAmerica', \"'s\", 'Ġbest', '-', 'known', 'Ġand', 'Ġmost', 'Ġinfluential', 'Ġpre', 'achers', '.', 'ĠA', 'ĠPul', 'pit', 'Ġ&', 'ĠPew', 'ĠResearch', 'Ġon', 'ĠPast', 'oral', 'ĠLeadership', 'Ġsurvey', 'Ġdetermined', 'Ġthat', 'Ġhe', 'Ġwas', 'Ġone', 'Ġof', 'Ġthe', 'Ġtwo', 'Ġmost', 'Ġfrequently', 'Ġread', 'Ġwriters', 'Ġby', 'Ġpastors', 'Ġin', 'Ġmainline', 'ĠProtestant', 'ism', 'Ġalongside', 'Ġthe', 'ĠRoman', 'ĠCatholic', 'Ġwriter', 'ĠHenri', 'ĠNou', 'wen', '.', 'ĠHis', 'Ġbooks', 'Ġhave', 'Ġsold', 'Ġover', 'Ġa', 'Ġmillion', 'Ġcopies', '.', 'ĠHe', 'Ġis', 'Ġalso', 'ĠEditor', '-', 'At', '-', 'Large', 'Ġof', 'Ġ\"', 'The', 'ĠChristian', 'ĠCentury', '\".', 'ĠHis', 'Ġ2019', 'Ġmemoir', 'Ġ\"', 'Acc', 'idental', 'ĠPre', 'acher', '\"', 'Ġwas', 'Ġreleased', 'Ġto', 'Ġwide', 'Ġacclaim', ',', 'Ġdescribed', 'Ġby', 'ĠJust', 'o', 'ĠL', '.', 'ĠGonzalez', 'Ġas', 'Ġ\"', 'An', 'Ġexceptional', 'Ġexample', 'Ġof', 'Ġtheology', 'Ġat', 'Ġits', 'Ġbest', '.\"', 'Bi', 'ography', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(chain(*tokenized_datasets[\"validation\"][\"input_ids\"][:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ċ']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5414308"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(chain(*tokenized_datasets[\"validation\"][\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 86291\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5230\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5256\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17121, 8616, 2561, 20473, 17121]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets['validation'][0]['input_ids'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['William', 'ĠHenry', 'ĠWill', 'imon', 'William']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(lm_datasets['validation'][0]['input_ids'][:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5230"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_datasets['validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity with Trainer pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_ppl_v3(model, tokenized_datasets, stride, device=device_id):\n",
    "    max_length = model.config.n_positions\n",
    "    nlls = []\n",
    "    encodings = list(chain(*(tokenized_datasets['validation']['input_ids'])))\n",
    "    n_words = len(encodings)\n",
    "\n",
    "    encodings = torch.tensor([encodings])\n",
    "    \n",
    "    for i in tqdm(range(0, n_words, stride)):\n",
    "        begin_loc = max(i + stride - max_length, 0)\n",
    "        end_loc = min(i + stride, n_words)\n",
    "        trg_len = end_loc - i  # may be different from stride on last loop\n",
    "        # input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        input_ids = encodings[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs[0] * trg_len\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5288/5288 [07:52<00:00, 11.19it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ppl = eval_ppl_v3(model, tokenized_datasets, stride=1024).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.71837043762207"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodings format 한번더 확 인\n",
    "encodings = list(chain(*tokenized_datasets[\"validation\"][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joon/PycharmProjects/imperial/m2d2/utils\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
