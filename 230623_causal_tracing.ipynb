{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 230623_causal_tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooking 방식 좀 더 안전하게 변경  \n",
    "tokenisation 할 때 max_sequence 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/jj1122/home/anaconda3/envs/m2d2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer, set_seed\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import datasets\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import date\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # module params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/dict_n_module_params_230623.json\", \"r\") as json_file:\n",
    "    dict_temp = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>is_in_layer</th>\n",
       "      <th>l</th>\n",
       "      <th>m</th>\n",
       "      <th>n_params</th>\n",
       "      <th>w_or_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformer.wte.weight</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>wte</td>\n",
       "      <td>38597376</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transformer.wpe.weight</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>wpe</td>\n",
       "      <td>786432</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transformer.h.0.ln_1.weight</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>ln_1</td>\n",
       "      <td>768</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer.h.0.ln_1.bias</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>ln_1</td>\n",
       "      <td>768</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer.h.0.attn.c_attn.weight</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>attn</td>\n",
       "      <td>1769472</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>transformer.h.11.mlp.c_fc.bias</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>mlp</td>\n",
       "      <td>3072</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>transformer.h.11.mlp.c_proj.weight</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>mlp</td>\n",
       "      <td>2359296</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>transformer.h.11.mlp.c_proj.bias</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>mlp</td>\n",
       "      <td>768</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>transformer.ln_f.weight</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>ln_f</td>\n",
       "      <td>768</td>\n",
       "      <td>weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>transformer.ln_f.bias</td>\n",
       "      <td>False</td>\n",
       "      <td>99</td>\n",
       "      <td>ln_f</td>\n",
       "      <td>768</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code  is_in_layer   l     m  n_params   \n",
       "0                transformer.wte.weight        False  -1   wte  38597376  \\\n",
       "1                transformer.wpe.weight        False  -1   wpe    786432   \n",
       "2           transformer.h.0.ln_1.weight         True   0  ln_1       768   \n",
       "3             transformer.h.0.ln_1.bias         True   0  ln_1       768   \n",
       "4    transformer.h.0.attn.c_attn.weight         True   0  attn   1769472   \n",
       "..                                  ...          ...  ..   ...       ...   \n",
       "143      transformer.h.11.mlp.c_fc.bias         True  11   mlp      3072   \n",
       "144  transformer.h.11.mlp.c_proj.weight         True  11   mlp   2359296   \n",
       "145    transformer.h.11.mlp.c_proj.bias         True  11   mlp       768   \n",
       "146             transformer.ln_f.weight        False  99  ln_f       768   \n",
       "147               transformer.ln_f.bias        False  99  ln_f       768   \n",
       "\n",
       "     w_or_b  \n",
       "0    weight  \n",
       "1    weight  \n",
       "2    weight  \n",
       "3      bias  \n",
       "4    weight  \n",
       "..      ...  \n",
       "143    bias  \n",
       "144  weight  \n",
       "145    bias  \n",
       "146  weight  \n",
       "147    bias  \n",
       "\n",
       "[148 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_code(row):\n",
    "    list_code = row.code.split(\".\")\n",
    "    is_in_layer = row[\"code\"].startswith(\"transformer.h\")\n",
    "    if is_in_layer:        \n",
    "        row[\"l\"] = int(list_code[2])\n",
    "        row[\"m\"] = list_code[3]\n",
    "    else:\n",
    "        row[\"m\"] = list_code[1]\n",
    "        if row[\"m\"] == \"ln_f\": \n",
    "            row[\"l\"] = int(99)\n",
    "        elif row[\"m\"] in [\"wte\", \"wpe\"]: \n",
    "            row['l'] = int(-1)\n",
    "    row[\"w_or_b\"] = list_code[-1]\n",
    "    row[\"is_in_layer\"] = is_in_layer\n",
    "    return row\n",
    "\n",
    "df_temp = pd.DataFrame.from_dict(dict_temp, orient=\"index\").reset_index()\n",
    "df_temp.columns = ['code', 'n_params']\n",
    "df_temp = df_temp.apply(lambda row: parse_code(row), axis=1)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_in_layer</th>\n",
       "      <th>m</th>\n",
       "      <th>n_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>ln_f</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>wpe</td>\n",
       "      <td>786432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>wte</td>\n",
       "      <td>38597376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>attn</td>\n",
       "      <td>2359296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>ln_1</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>ln_2</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>mlp</td>\n",
       "      <td>2359296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_in_layer     m  n_params\n",
       "0        False  ln_f       768\n",
       "1        False   wpe    786432\n",
       "2        False   wte  38597376\n",
       "3         True  attn   2359296\n",
       "4         True  ln_1       768\n",
       "5         True  ln_2       768\n",
       "6         True   mlp   2359296"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.loc[df_temp.w_or_b == \"weight\", [\"m\", \"n_params\", \"is_in_layer\"]]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby([\"is_in_layer\", \"m\"], as_index=False)[[\"n_params\"]].sum().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_code(row):\n",
    "    list_code = row.code.split(\".\")\n",
    "    row['l'] = int(list_code[2])\n",
    "    row['m'] = list_code[3]\n",
    "#     row['t'] = int(list_code[4])\n",
    "    return row\n",
    "\n",
    "list_df_ide_temp = []\n",
    "for i, d in enumerate(list_results_temp):\n",
    "    df_t = pd.DataFrame.from_dict(d['restored_loss'], orient='index')\n",
    "    TE = (corrupted_loss - clean_loss) / clean_loss\n",
    "    IDE = {}\n",
    "    for m_id in list_trace_module_ids:\n",
    "        IDE[m_id] = (restored_loss[m_id] - clean_loss) / clean_loss\n",
    "    \n",
    "    df_ide = pd.DataFrame.from_dict(IDE, orient='index').reset_index()\n",
    "    df_ide.columns = ['code', 'ide']\n",
    "    df_ide = df_ide.apply(lambda row: parse_code(row), axis=1)\n",
    "    df_ide[\"seq\"] = i\n",
    "    list_df_ide_temp.append(df_ide)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(718)\n",
    "set_seed(718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cd = \"omcd_econ_l1\"\n",
    "# job_cd = \"tmod_Religion_and_belief_systems\"\n",
    "# job_cd = sys.argv[2] # TODO\n",
    "\n",
    "list_job_cd = job_cd.split(\"_\")\n",
    "job_gubun = list_job_cd[0]\n",
    "model_id = \"_\".join(list_job_cd[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert job_gubun in [\"omcd\", \"tmod\"]\n",
    "\n",
    "cache_dir = \"/rds/general/user/jj1122/ephemeral/.cache/huggingface\"\n",
    "device_id = \"cpu\"\n",
    "\n",
    "n_layers = 12\n",
    "list_modules = ['attn', 'mlp']\n",
    "trace_module_id = \"transformer.h.{l}.{m}\"\n",
    "\n",
    "tuned_model_path = f\"/rds/general/user/jj1122/ephemeral/projects/m2d2/dataset/{model_id}/models\"\n",
    "\n",
    "today_dt = date.today().strftime(\"%y%m%d\")\n",
    "output_file = f\"/rds/general/user/jj1122/home/projects/m2d2/utils/output_logs/{today_dt}_{job_gubun}_{model_id}.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_trace_module_ids = []\n",
    "for l in range(n_layers):\n",
    "    for m in list_modules:\n",
    "        list_trace_module_ids.append(trace_module_id.format(l=l, m=m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset m2d2 (/rds/general/user/jj1122/ephemeral/.cache/huggingface/machelreid___m2d2/econ_l1/0.0.0/eb235f33a5de3163c10549b7f63c906910539c8a8c0ec5ade1285ccbf5067d00)\n",
      "100%|██████████| 3/3 [00:00<00:00, 677.27it/s]\n",
      "Loading cached processed dataset at /rds/general/user/jj1122/ephemeral/.cache/huggingface/machelreid___m2d2/econ_l1/0.0.0/eb235f33a5de3163c10549b7f63c906910539c8a8c0ec5ade1285ccbf5067d00/cache-1eec3cf03a698048.arrow\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "dataset = load_dataset(\"machelreid/m2d2\", model_id, cache_dir=cache_dir)\n",
    "ds_test = dataset[\"test\"].filter(lambda x: x['text'] != '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "set_seed(718)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    output = gpt2_tokenizer(examples['text'], max_length=1024, truncation=True)\n",
    "    return output\n",
    "\n",
    "tokenized_datasets = ds_test.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    remove_columns='text', #TODO\n",
    "    load_from_cache_file=True,\n",
    ")\n",
    "\n",
    "len_sentences = len(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL & HOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL & HOOK\n",
    "def load_model(model=\"tuned\"):\n",
    "    if model == \"tuned\":\n",
    "        return GPT2LMHeadModel.from_pretrained(tuned_model_path).to(device_id)\n",
    "    else:\n",
    "        return GPT2LMHeadModel.from_pretrained(model, cache_dir=cache_dir).to(device_id)\n",
    "\n",
    "\n",
    "def save_clean_activation(m_id):\n",
    "    def save_clean_activation_hook(module, _input, _output):\n",
    "        clean_activations[m_id] = _output\n",
    "    return save_clean_activation_hook\n",
    "\n",
    "\n",
    "def corrupt_input_vector_v2(module, _input, _output):\n",
    "    torch.manual_seed(718)\n",
    "    global before\n",
    "    global after\n",
    "    \n",
    "    std = torch.std(_output)\n",
    "    output = _output + (std*1.5) * torch.randn(_output[0].shape).to(device_id)\n",
    "    before = _output\n",
    "    after = output\n",
    "    return output\n",
    "\n",
    "\n",
    "def restore_activation(m_id):\n",
    "    def restore_activation_hook(module, _input, _output):\n",
    "        clean_activation = clean_activations[m_id]#[:, t]\n",
    "        return clean_activation\n",
    "    return restore_activation_hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "if job_gubun == \"omcd\":\n",
    "    clean_model = load_model()\n",
    "    clean_model.eval()\n",
    "    for m_id in list_trace_module_ids:\n",
    "        clean_model.get_submodule(m_id).register_forward_hook(save_clean_activation(m_id))    \n",
    "\n",
    "    # Second run: corrupted run def\n",
    "    corrupted_model = load_model()\n",
    "    corrupted_model.eval()\n",
    "    #         corrupted_model.get_submodule(\"transformer.h.0.attn\").register_forward_pre_hook(corrupt_input_vector)\n",
    "    corrupted_model.get_submodule(\"transformer.wte\").register_forward_hook(corrupt_input_vector_v2)\n",
    "\n",
    "    # Third run: restored run def    \n",
    "    restored_model = load_model()\n",
    "    #         restored_model.get_submodule(\"transformer.h.0.attn\").register_forward_pre_hook(corrupt_input_vector)\n",
    "    restored_model.get_submodule(\"transformer.wte\").register_forward_hook(corrupt_input_vector_v2)\n",
    "else:\n",
    "    clean_model = load_model()\n",
    "    clean_model.eval()\n",
    "    for m_id in list_trace_module_ids:\n",
    "        clean_model.get_submodule(m_id).register_forward_hook(save_clean_activation(m_id))\n",
    "\n",
    "    # Second run: base run def\n",
    "    corrupted_model = load_model(\"gpt2\")\n",
    "    corrupted_model.eval()\n",
    "\n",
    "    # Third run: restored run def\n",
    "\n",
    "    restored_model = load_model(\"gpt2\")\n",
    "    restored_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(output_file, 'r') as json_file:\n",
    "        list_results = json.load(json_file)\n",
    "    for i, d in enumerate(list_results):\n",
    "        if len(d) == 0:\n",
    "            done_idx = i - 1\n",
    "            break\n",
    "except:\n",
    "    list_results = [{} for x in range(len_sentences)]\n",
    "    done_idx = 0\n",
    "print(done_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_idx: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(718)\n",
    "set_seed(718)\n",
    "\n",
    "for sentence_idx, data in enumerate(tokenized_datasets):\n",
    "    if done_idx > sentence_idx: continue\n",
    "#         print(sentence_idx, data)\n",
    "#     print(sentence_idx)\n",
    "\n",
    "    if sentence_idx % 1000 == 0:\n",
    "        print(f\"sentence_idx: {sentence_idx}\")\n",
    "        with open(output_file, 'w') as json_file:\n",
    "            json.dump(list_results, json_file)\n",
    "\n",
    "    inputs = torch.tensor(data['input_ids']).to(device_id)\n",
    "\n",
    "    # First run: clean run\n",
    "    clean_activations = {}\n",
    "    with torch.no_grad():\n",
    "        clean_outputs = clean_model(inputs, labels=inputs.clone())\n",
    "        clean_loss = np.exp(clean_outputs.loss.item())\n",
    "\n",
    "    # Second run: corrupted run\n",
    "    with torch.no_grad():\n",
    "        corrupted_outputs = corrupted_model(inputs, labels=inputs.clone())\n",
    "        corrupted_loss = np.exp(corrupted_outputs.loss.item())\n",
    "\n",
    "    # Third run: corrupted-with-restoration run\n",
    "    restored_loss = {}\n",
    "    with torch.no_grad():\n",
    "        for m_id in list_trace_module_ids:\n",
    "            hook = restored_model.get_submodule(m_id).register_forward_hook(restore_activation(m_id))\n",
    "            restored_outputs = restored_model(inputs, labels=inputs.clone())\n",
    "            restored_loss[m_id] = np.exp(restored_outputs.loss.item())\n",
    "            hook.remove()\n",
    "\n",
    "    list_results[sentence_idx]['clean_loss'] = clean_loss\n",
    "    list_results[sentence_idx]['corrupted_loss'] = corrupted_loss\n",
    "    list_results[sentence_idx]['restored_loss'] = restored_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:m2d2]",
   "language": "python",
   "name": "conda-env-m2d2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
