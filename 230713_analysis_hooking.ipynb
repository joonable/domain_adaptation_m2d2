{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/jj1122/home/anaconda3/envs/m2d2_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import datasets\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from os import listdir\n",
    "import json\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 12\n",
    "list_modules = ['attn', 'mlp']\n",
    "trace_module_id = \"transformer.h.{l}.{m}\"\n",
    "\n",
    "list_trace_module_ids = []\n",
    "\n",
    "for l in range(n_layers):\n",
    "    for m in list_modules:\n",
    "        list_trace_module_ids.append(trace_module_id.format(l=l, m=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_trace_module_ids = ['transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj',\n",
    "       'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj',\n",
    "       'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj',\n",
    "       'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj',\n",
    "       'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj',\n",
    "       'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj',\n",
    "       'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj',\n",
    "       'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj',\n",
    "       'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj',\n",
    "       'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj',\n",
    "       'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj',\n",
    "       'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj',\n",
    "       'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj',\n",
    "       'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj',\n",
    "       'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj',\n",
    "       'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj',\n",
    "       'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj',\n",
    "       'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj',\n",
    "       'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj',\n",
    "       'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj',\n",
    "       'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj',\n",
    "       'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj',\n",
    "       'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj',\n",
    "       'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_tokeniser = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    output = gpt2_tokeniser(examples)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "\n",
    "def func_v1(m_id):\n",
    "    def hook_v1(module, _input, _output):\n",
    "        global seq\n",
    "        dict_sequence[m_id].append(seq)\n",
    "        seq += 1\n",
    "        \n",
    "        module_ = list(module) if isinstance(module, tuple) else module\n",
    "        input_ = list(_input) if isinstance(_input, tuple) else _input\n",
    "        output_ = list(_output) if isinstance(_output, tuple) else _output\n",
    "#         print(type(module_), module_)\n",
    "        temp[m_id] = [module_, input_, output_]\n",
    "        \n",
    "    return hook_v1\n",
    "\n",
    "gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "for m_id in list_trace_module_ids:\n",
    "    gpt2.get_submodule(m_id).register_forward_hook(func_v1(m_id))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5303, 23748],\n",
       "        [11274, 33847]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = [\"hi hello\", 'good bye']\n",
    "data = tokenize_function(input_text)\n",
    "inputs = torch.tensor(data['input_ids'])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sequence = {x: [] for x in list_trace_module_ids}\n",
    "seq = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    clean_outputs = gpt2(inputs, labels=inputs.clone())\n",
    "    clean_loss = np.exp(clean_outputs.loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.h.0.attn.c_attn': [0],\n",
       " 'transformer.h.0.attn.c_proj': [1],\n",
       " 'transformer.h.0.mlp.c_fc': [2],\n",
       " 'transformer.h.0.mlp.c_proj': [3],\n",
       " 'transformer.h.1.attn.c_attn': [4],\n",
       " 'transformer.h.1.attn.c_proj': [5],\n",
       " 'transformer.h.1.mlp.c_fc': [6],\n",
       " 'transformer.h.1.mlp.c_proj': [7],\n",
       " 'transformer.h.2.attn.c_attn': [8],\n",
       " 'transformer.h.2.attn.c_proj': [9],\n",
       " 'transformer.h.2.mlp.c_fc': [10],\n",
       " 'transformer.h.2.mlp.c_proj': [11],\n",
       " 'transformer.h.3.attn.c_attn': [12],\n",
       " 'transformer.h.3.attn.c_proj': [13],\n",
       " 'transformer.h.3.mlp.c_fc': [14],\n",
       " 'transformer.h.3.mlp.c_proj': [15],\n",
       " 'transformer.h.4.attn.c_attn': [16],\n",
       " 'transformer.h.4.attn.c_proj': [17],\n",
       " 'transformer.h.4.mlp.c_fc': [18],\n",
       " 'transformer.h.4.mlp.c_proj': [19],\n",
       " 'transformer.h.5.attn.c_attn': [20],\n",
       " 'transformer.h.5.attn.c_proj': [21],\n",
       " 'transformer.h.5.mlp.c_fc': [22],\n",
       " 'transformer.h.5.mlp.c_proj': [23],\n",
       " 'transformer.h.6.attn.c_attn': [24],\n",
       " 'transformer.h.6.attn.c_proj': [25],\n",
       " 'transformer.h.6.mlp.c_fc': [26],\n",
       " 'transformer.h.6.mlp.c_proj': [27],\n",
       " 'transformer.h.7.attn.c_attn': [28],\n",
       " 'transformer.h.7.attn.c_proj': [29],\n",
       " 'transformer.h.7.mlp.c_fc': [30],\n",
       " 'transformer.h.7.mlp.c_proj': [31],\n",
       " 'transformer.h.8.attn.c_attn': [32],\n",
       " 'transformer.h.8.attn.c_proj': [33],\n",
       " 'transformer.h.8.mlp.c_fc': [34],\n",
       " 'transformer.h.8.mlp.c_proj': [35],\n",
       " 'transformer.h.9.attn.c_attn': [36],\n",
       " 'transformer.h.9.attn.c_proj': [37],\n",
       " 'transformer.h.9.mlp.c_fc': [38],\n",
       " 'transformer.h.9.mlp.c_proj': [39],\n",
       " 'transformer.h.10.attn.c_attn': [40],\n",
       " 'transformer.h.10.attn.c_proj': [41],\n",
       " 'transformer.h.10.mlp.c_fc': [42],\n",
       " 'transformer.h.10.mlp.c_proj': [43],\n",
       " 'transformer.h.11.attn.c_attn': [44],\n",
       " 'transformer.h.11.attn.c_proj': [45],\n",
       " 'transformer.h.11.mlp.c_fc': [46],\n",
       " 'transformer.h.11.mlp.c_proj': [47]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attn_c_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_c_attn = \"transformer.h.0.attn.c_attn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1D()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[attn_c_attn][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.1000, -0.0874, -0.0269,  ..., -0.0154,  0.0138,  0.1415],\n",
       "          [ 0.1052, -0.1196, -0.0540,  ..., -0.1193,  0.0812,  0.0517]],\n",
       " \n",
       "         [[ 0.0065, -0.0714, -0.0597,  ..., -0.0201, -0.0945, -0.0281],\n",
       "          [ 0.0837, -0.2269, -0.0595,  ..., -0.3107, -0.1329,  0.0581]]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[attn_c_attn][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[attn_c_attn][1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output (activation, (k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6655, -0.2217,  0.1277,  ...,  0.0662, -0.0129,  0.0362],\n",
       "         [ 0.4013,  0.8140,  0.4187,  ..., -0.0534, -0.0017,  0.3631]],\n",
       "\n",
       "        [[-0.0903, -0.4669, -0.4292,  ..., -0.0223, -0.0383,  0.0397],\n",
       "         [-0.0209,  0.3601, -0.9751,  ...,  0.0634, -0.1967,  0.4776]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[attn_c_attn][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activation $ \\in \\mathbb{R}^{n\\_batch \\times n\\_tokens \\times dim\\_model}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2304])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[attn_c_attn][2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2MLP(\n",
       "  (c_fc): Conv1D()\n",
       "  (c_proj): Conv1D()\n",
       "  (act): NewGELUActivation()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['transformer.h.0.mlp'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input (n_tokens, dim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp['transformer.h.0.mlp'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['transformer.h.0.mlp'][1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output (n_tokens, dim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp['transformer.h.0.mlp'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['transformer.h.0.mlp'][2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1473, -0.8551,  0.2517,  ..., -1.0792,  0.4386, -0.8061],\n",
       "        [-0.9995, -0.4823, -1.1081,  ..., -0.7381, -0.0529, -1.1930]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['transformer.h.0.mlp'][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2d2_env",
   "language": "python",
   "name": "m2d2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
